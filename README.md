# Generating Human Motion Animation Using Echo State Networks and Conceptors

This project uses machine learning methods, such as *Echo State Networks* (*ESN*)
and *Conceptors* to generate human motion animations. The used *Motion Capture*
(*MoCap*) data is taken from the CMU Graphics Lab MoCap Database. The goal of the
project is to provide a through comparison of the above mentioned techniques.

## Repo Content
* src/ - Directory containing the implementation of all the methods.
    * thesisEsn.m - Implementation of the *ESN* approach.
    * thesisCon.m - Implementation of the *Conceptor* approach.
    * thesisRfc.m - (Incomplete) Implementation of the *Random Feature
    Conceptor* approach.
    * helpers/ - Helper functions used in the above scripts.
    * MoCapToolbox_v1.4/ - Toolbox used to render the generated motions.
* data/ - Normalized and cleaned training patterns
* video/ - Contains videos generated by the MATLAB code in src/.
    * esnVideo.mp4 - Video with motions generated by an ESN.
    * conVideo.mp4 - Video with motions generated using Conceptors.
* docs/ - Contains the written report of the project

